{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Logistic Regression in PyTorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Notebook we will be building a Neural Network on the MNIST dataset and implementing the logistic regression model.We will be including the forward and backward pass along with the loss function and optimizers.After training the model we will evaluate how we did and visualize what we've learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports of the packages we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST database (Modified National Institute of Standards and Technology database is a large database of handwritten digits that is commonly used for training various image processing systems.The MNIST database contains 60,000 training images and 10,000 testing images.\n",
    "\n",
    "![MNIST](Figures/MnistExamples.png)\n",
    "\n",
    "The first and foremost step in machine learning is preparing the data , this involves downloading, organzing, shuffling, processing the data so it can be fed into the model.\n",
    "The torchvision package makes this easy for us by implementing many of these , allowing us to put to use these datasets in only a few lines of code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "mnist_train = datasets.MNIST(root=\"./datasets\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test = datasets.MNIST(root=\"./datasets\", train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of MNIST Training Examples: 60000\n",
      "Number of MNIST Testing Exmaples: 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of MNIST Training Examples: {}\".format(len(mnist_train)))\n",
    "print(\"Number of MNIST Testing Exmaples: {}\".format(len(mnist_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected 60,000 of the MNIST examples are in the training set while the rest 10,000 are in the testing set. We added the transform ToTensor() to convert the input data from a PIL type into a PyTorch Tensor. Tensors are the input type that we feed into our model.\n",
    "\n",
    "Checking a random image from our train set. The shape of ourimage tensor returns to be something 3-Dimensional , To visualize this we need to remove the 1 which indicates \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Image Shape torch.Size([1, 28, 28])\n",
      "Reshaped Image Shape torch.Size([28, 28])\n",
      "The label for this Image 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image , label = mnist_train[435]\n",
    "print(\"Default Image Shape {}\".format(image.shape))\n",
    "image=image.reshape([28,28])\n",
    "print(\"Reshaped Image Shape {}\".format(image.shape))\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "print(\"The label for this Image {}\".format(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we could directly work with the date using `torchvision.dataset` we use `Data Loader` which makes it easier for shuffling and batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=100, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of minibatch drawn from a data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the mini batch of the images: torch.Size([100, 1, 28, 28])\n",
      "Shape of the mini batch of the labels: torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "data_train_iter = iter(train_loader)\n",
    "images , labels = data_train_iter.next()\n",
    "\n",
    "print(\"Shape of the mini batch of the images: {}\".format(images.shape))\n",
    "print(\"Shape of the mini batch of the labels: {}\".format(labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have loaded our data we will be building our Logistic Regression Model with no hidden layers.\n",
    "\n",
    "#### The Forward Pass\n",
    "\n",
    "While the data inputs are images i.e (2-Dimensional) we will be treating them as flat vectors. Thus to convert our inputs into row vectors we will use `view()` which is very similar to reshape in `numpy`.\n",
    "Also like numpy we replace one of the dimensions to a -1 which tells PyTorch to infer this dimension based on the orignal dimensions. Below is the flattening on the minibatch we drew above in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the input: torch.Size([100, 784])\n"
     ]
    }
   ],
   "source": [
    "x = images.view(-1, 28*28)\n",
    "print(\"The shape of the input: {}\".format(x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the predicted probabilities of each digit being a 0 like the image above. We start by applying a linear transformation.We multiply each pixel $x_i$ of the input row vector by a weight $w_i$ sum them all together and add a bias $b_1$. This is equivalent to a dot product between the class 0 weights and the input:\n",
    "\n",
    "\\begin{align}\n",
    "y_0 = \\sum_i x_i w_{i,0} + b_0\n",
    "\\end{align}\n",
    "\n",
    "The magnitude of the result $y_0$ will be taken as how likley do we consider the digit to be a 0. Since our goal is to identify all the digits , so we actually get:\n",
    "\n",
    "\\begin{align}\n",
    "y_0 = \\sum_i x_i w_{i,0} + b_0 \\\\\n",
    "y_1 = \\sum_i x_i w_{i,1} + b_1 \\\\\n",
    "y_2 = \\sum_i x_i w_{i,2} + b_2 \\\\\n",
    "y_3 = \\sum_i x_i w_{i,3} + b_3 \\\\\n",
    "y_4 = \\sum_i x_i w_{i,4} + b_4 \\\\\n",
    "y_5 = \\sum_i x_i w_{i,5} + b_5 \\\\\n",
    "y_6 = \\sum_i x_i w_{i,6} + b_6 \\\\\n",
    "y_7 = \\sum_i x_i w_{i,7} + b_7 \\\\\n",
    "y_8 = \\sum_i x_i w_{i,8} + b_8 \\\\\n",
    "y_9 = \\sum_i x_i w_{i,9} + b_9\n",
    "\\end{align}\n",
    "\n",
    "We can express this in the matrix form as: \n",
    " \\begin{align}y = x W + b\\end{align}\n",
    " \n",
    " Since Parallel Computations allow us to process multiple inputs at a time we can stack $x$ inputs with a matrix $X$ giving us:\n",
    " \\begin{align}y = X W + b\\end{align}\n",
    " \n",
    " Visualizing the dimensions: \n",
    " \n",
    " ![Dimension](Figures/mnist_matmul.png)\n",
    " \n",
    " \n",
    "In our example the minibatch size $m$ is $100$ and the dimension of the data is $28 * 28 = 784$ and the number of classes c is 10.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weight $W$ and bias $b$ make up the parameters of this model , when we say that we want to learn the model we refer to the fact that we need to find good values for every element in $W$ and $b$. Since we don't know what the best values are we are going to initialize $W$ randomly and set $b$ to a vector of zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly Iniitializes Weight\n",
    "W = torch.randn(784,10)/np.sqrt(784)\n",
    "W.requires_grad_()\n",
    "\n",
    "#Initializes bias b as zeros.\n",
    "b = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set `requires_grad` = `True` for both $W$ and $b$ since this tell's PyTorch to track the gradients for these two and all the variables depenedent on them.\n",
    "With these model parameters we can compute $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Transformation for W and b\n",
    "y = torch.matmul(x, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see what the first exmaple of our minibatch looks like , Remember bigger the number the more the model thinks the input $x$ is of that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2850,  0.0247,  0.1386, -0.3178,  0.5466, -0.1525,  0.1840, -0.2837,\n",
      "         0.1090, -0.3097], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(y[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can interpret these values as probabilities if we normalize them to be positive and add upto 1 , this is achieved in logistic regression with softmax:\n",
    "\n",
    "\\begin{align}\n",
    "p(y_i) = \\text{softmax}(y_i) = \\frac{\\text{exp}(y_i)}{\\sum_j\\text{exp}(y_j)}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the range of the exponential function is negative and we are normalizing by the sum , the softmax function achieves our goal of producing values between 0 to 1 that sum upto 1.\n",
    "PyTorch has an inbuilt softmax function  : `torch.nn.functional.softmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "py[0]: tensor([0.0749, 0.1021, 0.1144, 0.0725, 0.1720, 0.0855, 0.1197, 0.0750, 0.1110,\n",
      "        0.0730], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "py = torch.nn.functional.softmax(y, dim=1)\n",
    "print(\"py[0]: {}\".format(py[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Cross-Entropy Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we've done till now is randomly initialized the values of $W$ and $b$.Before we adjust any of the weights we need to see how the model is doing.We do this with a loss function to see how badly is the model performing.The loss function takes the model's prediction and returns a single number i.e a scalar summarizing the model performance. The loss which we use here is called cross-entropy loss which basically quantifies how farm away $y'$ is from $y$.\n",
    "\n",
    "\\begin{align}\n",
    "H_{y'}(y) = -\\sum_i y'_i\\text{log}(y_i)\n",
    "\\end{align}\n",
    "\n",
    "In our case $y$ is the set of probabilities predicted by the model and $y'$ are the targeted probabilities i.e the true labels.\n",
    "\\\n",
    "\\\n",
    "Cross-Entropy not only captures how correct(max probability = right answer) the model's answers are but also how confident the model was. This encourages the model to produce high probabilites for correct answers while driving down the probabilities for the wrong answers.\n",
    "\\\n",
    "\\\n",
    "Our focus here is on supervised learning, thus we have the labels. Our `dataloader` automatically includes the corresponding labels for each of the inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the softmax equation PyTorch has a builtin cross-entropy function: `torch.nn.functional.cross_entropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Entropy:2.3137755393981934\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = torch.nn.functional.cross_entropy(y, labels)\n",
    "print(\"Cross-Entropy:{}\".format(cross_entropy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that PyTorch's cross-entropy function combines the softmax function with cross_entropy that is why we feed in `y` instead of `py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Backward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have loss which quantifies how badly the model is doing , we can improve our model by chaning the parameters $W$ and $b$ to minimize the loss.The common way of doing this in neural networks is with Backpropagation: we take the gradient of the loss with respect wo $W$ and $b$ and take steps in the direction that reduces it.\n",
    "\\\n",
    "First we create an optimizer , since logistic regression is pretty simple we'll use standar stochastic gradient descent(SGD) which makes the following update:\n",
    "\n",
    "\\begin{align}\n",
    "\\theta_{t+1} = \\theta_t - \\alpha \\nabla_\\theta \\mathcal{L}\n",
    "\\end{align}\n",
    "\n",
    "where $\\theta$ is a parameter $\\alpha$ is our learning rate (step-size) and $\\nabla_\\theta$ $matchcal{L}$ is our gradient loss with respect to $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD([W,b], lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we created $W$ and $b$ we indicated that they needed gradients, to compute their gradients we use `backward()` function on the cross entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the variables that required gradients have accumulated gradients now, we can see this in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0880, -0.0504,  0.0091,  0.0159,  0.1036, -0.0092,  0.0516, -0.0201,\n",
       "        -0.0194,  0.0069])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the gradients using our optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set our learnaing rate as 0.1 , hence $b$ has been updated by `-0.1*b.grad`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0352,  0.0202, -0.0037, -0.0064, -0.0414,  0.0037, -0.0206,  0.0080,\n",
       "         0.0078, -0.0028], requires_grad=True)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now successfully trained the model on a minibatch i.e a 100 exmaples out of the 60,000.\n",
    "/\n",
    "Note: The gradients calculated by `backward()` dont override the old values instead they accumulate. Thefore you'll want to clear the gradient buffers before you compute gradients for the next minibatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b.grad before zero_grad():tensor([-0.0880, -0.0504,  0.0091,  0.0159,  0.1036, -0.0092,  0.0516, -0.0201,\n",
      "        -0.0194,  0.0069])\n",
      "b.grad after zero_grad():tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(\"b.grad before zero_grad():{}\".format(b.grad))\n",
    "optimizer.zero_grad()\n",
    "print(\"b.grad after zero_grad():{}\".format(b.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training\n",
    "\n",
    "To train the model we just need to repeat what we just did for the other mini batches from the training set. The steps were as follows:\n",
    "1. Draw a mini batch.\n",
    "2. Zero the gradients in the buffer for `W` and `b`.\n",
    "3. Perform the forward pass (compute prediction, calculate loss)\n",
    "4. Perfom the backward pass (compute gradients, perform SGD step)\n",
    "\n",
    "Going through the entire dataset once is known as an epoch.\n",
    "We will wrap the `train_loader` with `tqdm` which adds a handy progress bar so we can track our training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d0f65439ac4b94928836f3be16ebb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for images, labels in tqdm(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    x = images.view(-1,28*28)\n",
    "    y = torch.matmul(x, W) + b\n",
    "    cross_entropy = torch.nn.functional.cross_entropy(y, labels)\n",
    "    \n",
    "    cross_entropy.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
